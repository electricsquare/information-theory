<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Tom Read Cutting">
  <title>How Information Works</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reset.css">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="css/style.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section id="title" class="slide level3" data-background-image="img/Information_Slide.png" data-background-size="contain" data-background-transition="none">
<h3 data-background-image="img/Information_Slide.png" data-background-size="contain" data-background-transition="none"></h3>
</section>
<section id="title-video" class="slide level3" data-background-video="img/Information_Slide.webm" data-background-size="contain" data-background-video-loop="loop">
<h3 data-background-video="img/Information_Slide.webm" data-background-size="contain" data-background-video-loop="loop"></h3>
</section>
<section id="what-is" class="slide level3">
<h3>What Is?</h3>
<p>Understanding the movement and transformation of information through mathematical and physical laws, addressing and answering two fundamental questions:</p>
<div class="fragment">
<ol type="1">
<li><strong>How can much can you compress data? (The entropy of the data, H).</strong></li>
</ol>
</div>
<div class="fragment">
<ol start="2" type="1">
<li>At which rate can you reliable communicate through a channel? (The channel capacity, C).</li>
</ol>
<aside class="notes">
<p>What is information theory?</p>
<p>We will only cover the first question. Question two can be saved for further reading, or a later talk…</p>
</aside>
</div>
</section>
<section id="why-do" class="slide level3">
<h3>Why Do?</h3>
<p>Widely Applicable! (Sneak Peak):</p>
<div class="fragment">
<ul>
<li>Compression (duh!)</li>
<li>Communications and Networking (duh!)</li>
<li>Data Oriented Design</li>
<li>Security</li>
<li>Machine Learning (huh?)</li>
<li>Computer Vision (huh?)</li>
<li>Computer Graphics (huh!?)</li>
<li>^^ Almost Everything in Computer Science</li>
</ul>
<aside class="notes">
<p>Information Theory has some pretty obvious applications, but hopefully some here will surprise you!</p>
<p><em>click</em></p>
<p>We will be delving into the more interesting links later, and go in depth on these.</p>
<p>Outside of Computer Science, relevant to subjects from linguistics, to physics and how the universe itself works!</p>
<p>TODO: https://www.youtube.com/watch?v=sMb00lz-IfE</p>
</aside>
</div>
</section>
<section id="what-contains" class="slide level3">
<h3>What Contains?</h3>
<ul>
<li>Foundations: Intro, Bayes, Entropy, Shannon’s Source Coding Theorem</li>
<li>Applications: Codes, Compression</li>
<li>Relations: DoD, Security, ML, Graphics</li>
</ul>
<div class="fragment">
<p><em>Not</em> mathematically rigorous! Arguments rely on intuition, <em>not</em> formal proof. User-friendly, <em>not</em> technically precise.</p>
<aside class="notes">
<p>Very high level overview, will give you taste of what doors Information theory opens-up.</p>
<p>Applicable outside of Computer Science, is important to understanding reality itself! TODO: https://www.youtube.com/watch?v=yWO-cvGETRQ</p>
<p><em>click</em></p>
<p>Not maths accurate!</p>
</aside>
</div>
</section>
<section>
<section id="foundations" class="title-slide slide level2">
<h2>Foundations</h2>

</section>
<section id="data-is-not-information" class="slide level3">
<h3>Data Is Not Information</h3>
<p><strong>Intuition:</strong> A new hard drive has 1,000,000,000,000 bits of data, but not 1,000,000,000,000.</p>
<p>Is there a difference between a 0-initialized hard drive, and a randomly-initialized hard drive in terms of information?</p>
<aside class="notes">
<p>This concept makes sense to use intuitively.</p>
<p>Answer to question, yes, if you care about the value of the bits on the randomly-initialized hard drive.</p>
<p>But this does hint an something interesting regarding information…</p>
</aside>
</section>
<section id="probabilities-matter" class="slide level3">
<h3>Probabilities Matter</h3>
<p>The less probable an event is, the more information it contains when it happens.</p>
<aside class="notes">
<p>Intuition: I tell you my name is Tom, the fact that you were expecting that means that the particular piece of information that I go by that name now isn’t very high.</p>
<p>However, if I were to tell you that my name is now Geoffrey, that would be more information.</p>
</aside>
</section>
<section id="bit-1-bit" class="slide level3">
<h3>1 Bit ≠ 1 Bit</h3>
<p>1 Bit of Data is not 1 Bit of Information.</p>
<div class="fragment">
<p>We can say that 1 Bit of Data contains 1 Bit of Information if the probability of that Bit being 1 or 0 is 0.5.</p>
<aside class="notes">
<p>Clickbait title! 1 Bit is not 1 Bit?</p>
<p><em>click</em></p>
<p>We will expand on what that is later. But this is the core of things like compression algorithms, if the probabilities of any bit in a bit stream being a given value isn’t 0.5 what does that mean?</p>
<p>You will understand this later.</p>
</aside>
</div>
</section>
<section id="knowledge-affects-information" class="slide level3">
<h3>Knowledge Affects Information</h3>
<p>Intuitively, past events affect the probabilities by which we predict future events.</p>
<div class="fragment">
<p>In othr wrds, yo cn rd ths sntnce evn wth mssng lttrs.</p>
<aside class="notes">
<p>Here’s intuitively why probability is important</p>
<p><em>click</em></p>
<p>The reason why you can read this sentence is because there are probabilies associated with what the missing letters could be, and your brain automatically fills in the gaps with the most likely options.</p>
<p>I find it awesome that our brains can run super-hardcore bayesian inference like that without us even thinking about it.</p>
</aside>
</div>
</section></section>
<section>
<section id="some-probability" class="title-slide slide level2">
<h2>Some Probability</h2>
<aside class="notes">
<p>We are going to delve into some probility basics.</p>
<p>Bear with me as this is imporant to understand, I’m going to go over this thoroughly as it helps a lot. But if you do get lost, I will stick to intuitive explenations for the rest of the talk.</p>
</aside>
</section>
<section id="basic-syntax---pa" class="slide level3">
<h3>Basic Syntax - <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A)</annotation></semantics></math></h3>
<p>For some event <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A)</annotation></semantics></math> says how likely that event is to occur.</p>
<div class="fragment">
<p>In other words, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A)</annotation></semantics></math> represents the probability that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> will happen.</p>
</div>
<div class="fragment">
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mi>m</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p(um)=1</annotation></semantics></math></p>
<aside class="notes">
<p>Read Slide</p>
<p><em>click</em></p>
<p>Read Slide</p>
<p><em>click</em></p>
<p>If the event is that I will use say “umm” during this talk, then we can say that the probability of “umm”, p(um), is 1.</p>
</aside>
</div>
</section>
<section id="basic-syntax---pab" class="slide level3">
<h3>Basic Syntax - <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A,B)</annotation></semantics></math></h3>
<p>For events <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A,B)</annotation></semantics></math> is how likely both events are to happen.</p>
<div class="fragment">
<p>Hopefully <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mi>a</mi><mi>l</mi><mi>k</mi><mo>,</mo><mi>s</mi><mi>w</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(talk,swear)</annotation></semantics></math> is low.</p>
</div>
</section>
<section id="basic-syntax---pab-1" class="slide level3">
<h3>Basic Syntax - <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="prefix">|</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A|B)</annotation></semantics></math></h3>
<p>oh no</p>
</section>
<section id="product-rule" class="slide level3">
<h3>Product Rule</h3>
<p>The probability that both <em>A</em> and <em>B</em> will happen:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="prefix">|</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="prefix">|</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A,B) = p(A|B)p(B) = p(B|A)p(A)</annotation></semantics></math></p>
<p>Example: The Probability that Alice will buy a hot dog <em>and</em> ketchup?</p>
<aside class="notes">
<p>If we know the probability of Alice buying ketchup given that she’s bought a hot dog. <em>And</em> we know how likely she is to buy a hot dog. Then we know how likely <em>both</em> are to happen.#</p>
<p>TODO: https://www.youtube.com/watch?v=_PG-jJKB_do</p>
</aside>
</section>
<section id="sum-rule" class="slide level3">
<h3>Sum Rule</h3>
<p>If the probability of A is affected by the outcome of a number of events <em>B</em></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munder><mo>∑</mo><mi>B</mi></munder><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munder><mo>∑</mo><mi>B</mi></munder><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="prefix">|</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(A) = \sum\limits_{B} p(A,B) = \sum_{B} p(A|B)p(B)</annotation></semantics></math></p>
<p>Example: The Probability that Bob will beat Alice at chess.</p>
<aside class="notes">
<p>If we know the probability that Bob will beat Alice when starting with whites, and the probability that Bob will beat Alice when starting with blacks - then we know the probability that Bob will beat Alice if we know how likely he is to start with either of those colours.</p>
</aside>
</section>
<section id="bayes-theorem" class="slide level3">
<h3>Bayes’ Theorem</h3>
<p>Super-duper important, we aren’t going to derive it, but have a look at this majestic thing:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="prefix">|</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="prefix">|</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">p(B|A) = \frac{p(A|B)(p(B)}{p(A)}</annotation></semantics></math></p>
<aside class="notes">
<p>Derived from the product and sum rules.</p>
</aside>
</section>
<section id="relation-to-information-theory" class="slide level3">
<h3>Relation to Information Theory</h3>
<p>Bayes’ Theorem can be applied recursively to let us use the latest posterior as a new <em>prior</em> so interpret the next set of data.</p>
<p>Information Theory is about quantitatively analysing the amount of information gained (via analysing reduced uncertainty) using Bayes’ Theorem.</p>
</section></section>
<section>
<section id="entropy" class="title-slide slide level2">
<h2>Entropy</h2>

</section>
<section id="event-information" class="slide level3">
<h3>Event Information</h3>
<p>The information <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> contained within an event is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>=</mo><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">I = \log_2(p)</annotation></semantics></math></p>
<p>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> is the probability of that event occurring.</p>
<p>Entropy, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">H = -I</annotation></semantics></math> is the the amount of uncertainty.</p>
</section>
<section id="adding-information" class="slide level3">
<h3>Adding Information</h3>
<p>For independent <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mrow><mi>a</mi><mi>b</mi></mrow></msub><mo>=</mo><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>p</mi><mi>a</mi></msub><msub><mi>p</mi><mi>b</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>p</mi><mi>a</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>p</mi><mi>b</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mi>I</mi><mi>a</mi></msub><mo>+</mo><msub><mi>I</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">I_{ab} = \log_2(p_a p_b) = \log_2(p_a) + \log_2(p_b) = I_a + I_b</annotation></semantics></math></p>
<aside class="notes">
<p>By defining information in terms of the logarithms of the underlying probabilities involved, we can “add” information together to get the total information gain of two events.</p>
</aside>
</section>
<section id="entropy-of-ensembles" class="slide level3">
<h3>Entropy of Ensembles</h3>
<p>If you have non-uniform ensemble of probabilities such that:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum\limits_i p_i = 1 </annotation></semantics></math></p>
<p>Then:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>p</mi><mi>i</mi></msub><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H = - \sum\limits_i p_i \log_2(p_i)</annotation></semantics></math></p>
<aside class="notes">
<p>TODO: Intuition</p>
</aside>
</section>
<section id="intuition" class="slide level3">
<h3>Intuition</h3>
<p>Bit, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">b=1</annotation></semantics></math> with probability <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> (and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math> otherwise):</p>
<figure>
<img data-src="plots/-6161266816559618684.svg" class="matplotlib" height="200" alt="" /><figcaption><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>−</mo><mi>p</mi><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo><msub><mo>log</mo><mn>2</mn></msub><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H(p)=-p\log_2(p)-(1-p)\log_2(1-p)</annotation></semantics></math></figcaption>
</figure>
<p>When <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">p=0.5</annotation></semantics></math>, the Entropy maxes-out at 1.</p>
<aside class="notes">
<p>Bring that back to earlier when we said that 1 bit of data contains 1 bit of information if the probability of it being 1 or 0 was 0.5, this is why!</p>
</aside>
</section>
<section id="further-entropy-reading" class="slide level3">
<h3>Further Entropy Reading</h3>
<ul>
<li>Joint Entropy</li>
<li>Conditional Entropy of Ensembles</li>
<li>Chain Rule for Entropy</li>
<li>Mutual Information</li>
<li>Kullback-Leibler Distance and Fano’s Inequality</li>
</ul>
</section></section>
<section>
<section id="source-coding" class="title-slide slide level2">
<h2>Source-Coding</h2>

</section>
<section id="codes" class="slide level3">
<h3>Codes</h3>
<p>Stream of data can produce <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math>, with:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">p(A)=\frac{1}{2}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">p(B)=\frac{1}{4}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>C</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">p(C)=\frac{1}{8}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>D</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">p(D)=\frac{1}{8}</annotation></semantics></math></li>
</ul>
</section>
<section id="encoding-as-binary" class="slide level3">
<h3>Encoding as Binary</h3>
<p>A naive code might look like this:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mn>00</mn></mrow><annotation encoding="application/x-tex">A = 00</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mn>01</mn></mrow><annotation encoding="application/x-tex">B = 01</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">C = 10</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mn>11</mn></mrow><annotation encoding="application/x-tex">D = 11</annotation></semantics></math></li>
</ul>
<p>This has a fixed <em>code rate</em>, (the mean number of bits transmitted), <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">R=2</annotation></semantics></math>.</p>
<aside class="notes">
<p>TODO: Convert this to a tables=</p>
</aside>
</section>
<section id="entropy-of-the-system" class="slide level3">
<h3>Entropy of the system</h3>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mi>.</mi><mi>.</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">H=...</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>C</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>D</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">=H(A)+H(B)+H(C)+H(D)</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>−</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mn>2</mn><mo>−</mo><mfrac><mn>1</mn><mn>8</mn></mfrac><mn>3</mn><mo>−</mo><mfrac><mn>1</mn><mn>8</mn></mfrac><mn>3</mn></mrow><annotation encoding="application/x-tex">=-\frac{1}{2}-\frac{1}{4}2-\frac{1}{8}3-\frac{1}{8}3</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>−</mo><mfrac><mn>3</mn><mn>8</mn></mfrac><mo>−</mo><mfrac><mn>3</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">=-\frac{1}{2}-\frac{1}{2}-\frac{3}{8}-\frac{3}{8}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>−</mo><mn>1.75</mn></mrow><annotation encoding="application/x-tex">=-1.75</annotation></semantics></math></li>
</ul>
</section>
<section id="coding-efficiency" class="slide level3">
<h3>Coding Efficiency</h3>
<p>The efficiency <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>μ</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math> of our coding is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mfrac><mi>H</mi><mi>R</mi></mfrac></mrow><annotation encoding="application/x-tex">\mu=\frac{H}{R}</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mn>1.75</mn><mi>/</mi><mn>2</mn><mo>=</mo><mn>0.875</mn></mrow><annotation encoding="application/x-tex">\mu=1.75/2=0.875</annotation></semantics></math></p>
<aside class="notes">
<p>The implication is that a coding <em>should</em> exist that itself has a coding rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">R=H</annotation></semantics></math>, and if we can find-it, it will be optimal.</p>
</aside>
</section>
<section id="variable-length-coding" class="slide level3">
<h3>Variable-Length Coding</h3>
<p>Now imagine:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">A = 0</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">B = 10</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>110</mn></mrow><annotation encoding="application/x-tex">C = 110</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mn>111</mn></mrow><annotation encoding="application/x-tex">D = 111</annotation></semantics></math></li>
</ul>
<div class="fragment">
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mn>2</mn><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mn>3</mn><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>C</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mn>3</mn><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>D</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>1.75</mn></mrow><annotation encoding="application/x-tex">R=p(A)+2p(B)+3p(C)+3p(D)=1.75</annotation></semantics></math></p>
<aside class="notes">
<p>Explain variable length coding, and useful properties (each symbol uniquely and instantaneously decodable).</p>
<p><hit next></p>
<p>Look, it’s entropy matches R!</p>
</aside>
</div>
</section>
<section id="shannons-source-coding-theorem" class="slide level3">
<h3>Shannon’s Source-Coding Theorem</h3>
<p><em>You can compress a stream of data with entropy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> into a code whose rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math> approaches <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> in the limit, but you can’t have a code rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>&lt;</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">R &lt; H</annotation></semantics></math> without loss of information.</em></p>
</section>
<section id="on-fixed-probabilities" class="slide level3">
<h3>On Fixed Probabilities</h3>
<p>Probabilities in symbol streams rarely fixed</p>
<ul>
<li>Could be affected by previous symbol (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>U</mi><mo stretchy="false" form="prefix">|</mo><mi>Q</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(U|Q)</annotation></semantics></math> is high!)</li>
<li>Can be dependant on context, the <em>type</em> of data: photos vs cartoons.</li>
<li>Can depend on recipient (encryption!)</li>
</ul>
<aside class="notes">
<p>The goal of encryption is transmit data in such a way that it contains no information for anyone except the intended receiver.</p>
<p>This is unfortunately the limits we will get to with lossless compression, but you can see the foundations of a mathematical system for understanding this stuff.</p>
<p>Good compression systems are as much about trying to accurately <em>discern</em> the entropy of each symbol for the target recipient.</p>
</aside>
</section>
<section id="further-coding-reading" class="slide level3">
<h3>Further Coding Reading</h3>
<ul>
<li>Huffman Codes &amp; Huffman Trees</li>
<li>Kraft-McMillan Inequality</li>
<li>Markov Chains</li>
</ul>
</section></section>
<section>
<section id="noise-and-error-correction" class="title-slide slide level2">
<h2>Noise and Error Correction</h2>

</section>
<section id="binary-symmetric-channels" class="slide level3">
<h3>Binary-Symmetric Channels</h3>
<p>Generically, channel… (put in some) TODO</p>
</section>
<section id="channel-capacity" class="slide level3">
<h3>Channel Capacity</h3>
<p>TODO</p>
</section>
<section id="shannons-channel-coding-theorem" class="slide level3">
<h3>Shannon’s Channel Coding Theorem</h3>
<p>TODO</p>
</section>
<section id="hamming-code" class="slide level3">
<h3>Hamming Code</h3>
<p>TODO</p>
</section>
<section id="error-correcting-codes" class="slide level3">
<h3>Error-Correcting Codes</h3>
<p>TODO</p>
</section>
<section id="further-noise-and-error-correction-reading" class="slide level3">
<h3>Further Noise and Error-Correction Reading</h3>
<p>TODO</p>
</section></section>
<section>
<section id="compression" class="title-slide slide level2">
<h2>Compression</h2>

</section>
<section id="todo-compression" class="slide level3">
<h3>TODO Compression</h3>
<p>TODO</p>
</section></section>
<section>
<section id="relations" class="title-slide slide level2">
<h2>Relations</h2>

</section>
<section id="original-list" class="slide level3">
<h3>Original List</h3>
<ul>
<li>Compression (duh!)</li>
<li>Communications and Networking (duh!)</li>
<li>Data Oriented Design</li>
<li>Security</li>
<li>Machine Learning (huh?)</li>
<li>Computer Vision (huh?)</li>
<li>Computer Graphics (huh!?)</li>
<li>^^ Almost Everything in Computer Science</li>
</ul>
</section>
<section id="todo-how-these-all-relate" class="slide level3">
<h3>TODO How these all relate</h3>
</section></section>
<section>
<section id="the-end" class="title-slide slide level2">
<h2>The End</h2>

</section>
<section id="special-thanks" class="slide level3">
<h3>Special Thanks</h3>
<ul>
<li>Professor John Daugman for teaching this course at University.</li>
<li>Alastair Toft &amp; AJ Weeks for ideas bouncing and feedback.</li>
<li>Huw Bowles for organising these talks and providing invaluable feedback.</li>
</ul>
</section>
<section id="social-media" class="slide level3">
<h3>Social Media</h3>
<p>Subscribe to our <a href="https://www.youtube.com/channel/UCahevy2N_tj_ZOdsByl9L-A">YouTube Channel</a>!</p>
<p>More talks available! Chips! Git!</p>
</section>
<section id="references" class="slide level3">
<h3>References</h3>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-DaugmanJohn2016">
<p>Daugman, John. 2016. “Information Theory.” <a href="https://www.cl.cam.ac.uk/teaching/1617/InfoTheory/materials.html">https://www.cl.cam.ac.uk/teaching/1617/InfoTheory/materials.html</a>.</p>
</div>
</div>
</section>
<section id="careers" class="slide level3" data-background-color="#000">
<h3 data-background-color="#000">Careers</h3>
<p><a href="mailto:careers@electricsquare.com">careers@electricsquare.com</a></p>
</section></section>
    </div>
  </div>

  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
